{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3319656",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-15T02:10:56.489491Z",
     "iopub.status.busy": "2024-01-15T02:10:56.489181Z",
     "iopub.status.idle": "2024-01-15T02:10:57.697730Z",
     "shell.execute_reply": "2024-01-15T02:10:57.696935Z"
    },
    "papermill": {
     "duration": 1.22121,
     "end_time": "2024-01-15T02:10:57.700138",
     "exception": false,
     "start_time": "2024-01-15T02:10:56.478928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e00c01be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:10:57.718211Z",
     "iopub.status.busy": "2024-01-15T02:10:57.717828Z",
     "iopub.status.idle": "2024-01-15T02:11:15.365222Z",
     "shell.execute_reply": "2024-01-15T02:11:15.364342Z"
    },
    "papermill": {
     "duration": 17.659046,
     "end_time": "2024-01-15T02:11:15.367646",
     "exception": false,
     "start_time": "2024-01-15T02:10:57.708600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import tifffile as tiff\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58760251",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:11:15.386054Z",
     "iopub.status.busy": "2024-01-15T02:11:15.385504Z",
     "iopub.status.idle": "2024-01-15T02:11:15.394853Z",
     "shell.execute_reply": "2024-01-15T02:11:15.394095Z"
    },
    "papermill": {
     "duration": 0.020338,
     "end_time": "2024-01-15T02:11:15.396610",
     "exception": false,
     "start_time": "2024-01-15T02:11:15.376272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run-length Encode and Decode functions\n",
    "\n",
    "# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    " \n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80334542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:11:15.413996Z",
     "iopub.status.busy": "2024-01-15T02:11:15.413683Z",
     "iopub.status.idle": "2024-01-15T02:11:15.417496Z",
     "shell.execute_reply": "2024-01-15T02:11:15.416760Z"
    },
    "papermill": {
     "duration": 0.014686,
     "end_time": "2024-01-15T02:11:15.419437",
     "exception": false,
     "start_time": "2024-01-15T02:11:15.404751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"/kaggle/input/blood-vessel-segmentation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "496d445f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:11:15.436696Z",
     "iopub.status.busy": "2024-01-15T02:11:15.436453Z",
     "iopub.status.idle": "2024-01-15T02:11:16.605399Z",
     "shell.execute_reply": "2024-01-15T02:11:16.604508Z"
    },
    "papermill": {
     "duration": 1.180048,
     "end_time": "2024-01-15T02:11:16.607528",
     "exception": false,
     "start_time": "2024-01-15T02:11:15.427480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kidney_1_dense_0000</td>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kidney_1_dense_0001</td>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kidney_1_dense_0002</td>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kidney_1_dense_0003</td>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kidney_1_dense_0004</td>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  rle\n",
       "0  kidney_1_dense_0000  1 0\n",
       "1  kidney_1_dense_0001  1 0\n",
       "2  kidney_1_dense_0002  1 0\n",
       "3  kidney_1_dense_0003  1 0\n",
       "4  kidney_1_dense_0004  1 0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_rles = pd.read_csv(os.path.join(data_dir + \"train_rles.csv\"))\n",
    "df_train_rles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9dfd978",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:11:16.634216Z",
     "iopub.status.busy": "2024-01-15T02:11:16.633698Z",
     "iopub.status.idle": "2024-01-15T02:11:16.644825Z",
     "shell.execute_reply": "2024-01-15T02:11:16.643767Z"
    },
    "papermill": {
     "duration": 0.029143,
     "end_time": "2024-01-15T02:11:16.647243",
     "exception": false,
     "start_time": "2024-01-15T02:11:16.618100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kidney_3_dense', 'kidney_1_dense', 'kidney_2', 'kidney_1_voi', 'kidney_3_sparse']\n"
     ]
    }
   ],
   "source": [
    "# df_train_rles[ [\"kidney_dataset\", \"image_no\"]] = df_train_rles['id'].str.rsplit(pat='_', n=1, expand=True)\n",
    "train_data_path = os.path.join(data_dir + \"/train\")\n",
    "dataset = os.listdir(train_data_path)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "072ca21c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:11:16.673902Z",
     "iopub.status.busy": "2024-01-15T02:11:16.673159Z",
     "iopub.status.idle": "2024-01-15T02:11:16.680692Z",
     "shell.execute_reply": "2024-01-15T02:11:16.679597Z"
    },
    "papermill": {
     "duration": 0.027325,
     "end_time": "2024-01-15T02:11:16.687202",
     "exception": false,
     "start_time": "2024-01-15T02:11:16.659877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = {}\n",
    "    \n",
    "for i in range(len(dataset)):\n",
    "    key = dataset[i]\n",
    "    value1 = os.path.join(train_data_path, dataset[i] + \"/images\")\n",
    "    value2 = os.path.join(train_data_path, dataset[i] + \"/labels\")\n",
    "    paths[key] = [value1, value2]\n",
    "\n",
    "paths['kidney_3_dense'][0] = paths['kidney_3_sparse'][0]\n",
    "images_path, labels_path = paths['kidney_3_dense']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3eabedb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:11:16.713381Z",
     "iopub.status.busy": "2024-01-15T02:11:16.713104Z",
     "iopub.status.idle": "2024-01-15T02:11:16.984048Z",
     "shell.execute_reply": "2024-01-15T02:11:16.983050Z"
    },
    "papermill": {
     "duration": 0.286896,
     "end_time": "2024-01-15T02:11:16.986901",
     "exception": false,
     "start_time": "2024-01-15T02:11:16.700005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_files_kidney_3_dense = sorted([os.path.join(images_path, f) for f in os.listdir(images_path) if f.endswith('.tif')])\n",
    "label_files_kidney_3_dense = sorted([os.path.join(labels_path, f) for f in os.listdir(labels_path) if f.endswith('.tif')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33faf59f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:11:17.010627Z",
     "iopub.status.busy": "2024-01-15T02:11:17.009731Z",
     "iopub.status.idle": "2024-01-15T02:11:18.290607Z",
     "shell.execute_reply": "2024-01-15T02:11:18.289763Z"
    },
    "papermill": {
     "duration": 1.293949,
     "end_time": "2024-01-15T02:11:18.293080",
     "exception": false,
     "start_time": "2024-01-15T02:11:16.999131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(len(image_files_kidney_3_dense)):\n",
    "    for j in range(len(label_files_kidney_3_dense)):\n",
    "        if os.path.basename(label_files_kidney_3_dense[j]) == os.path.basename(image_files_kidney_3_dense[i]):\n",
    "            l.append(image_files_kidney_3_dense[i])\n",
    "\n",
    "image_files_kidney_3_dense = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10aa3b3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:11:18.311428Z",
     "iopub.status.busy": "2024-01-15T02:11:18.310920Z",
     "iopub.status.idle": "2024-01-15T02:11:18.315247Z",
     "shell.execute_reply": "2024-01-15T02:11:18.314459Z"
    },
    "papermill": {
     "duration": 0.015504,
     "end_time": "2024-01-15T02:11:18.317145",
     "exception": false,
     "start_time": "2024-01-15T02:11:18.301641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c099f82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:11:18.334924Z",
     "iopub.status.busy": "2024-01-15T02:11:18.334653Z",
     "iopub.status.idle": "2024-01-15T02:11:18.343007Z",
     "shell.execute_reply": "2024-01-15T02:11:18.342027Z"
    },
    "papermill": {
     "duration": 0.019356,
     "end_time": "2024-01-15T02:11:18.344869",
     "exception": false,
     "start_time": "2024-01-15T02:11:18.325513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageProcessor(object):\n",
    "    def __init__(self,image_path):\n",
    "        self.image_path = image_path\n",
    "        self.image = self.read_image()\n",
    "    \n",
    "    def read_image(self):\n",
    "        img = mpimg.imread(self.image_path)\n",
    "        #img = img.astype(np.float64)\n",
    "        return img\n",
    "    \n",
    "    def normalize_image(self):\n",
    "        image = self.image.astype(np.float64)\n",
    "        normalized_img = (image-np.mean(image))/np.std(image)\n",
    "        return normalized_img\n",
    "    \n",
    "    def display_images(self, normalized = False, array = False):\n",
    "        if not array:\n",
    "            if normalized:\n",
    "                normalized_img = self.normalize_image()\n",
    "                plt.imshow(normalized_img)\n",
    "                plt.title(\"Normalized Image\")\n",
    "            else:\n",
    "                plt.imshow(self.image)\n",
    "                plt.title(\"Original Image\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "        \n",
    "        else:\n",
    "            if normalized:\n",
    "                normalized_img = self.normalize_image()\n",
    "                return normalized_img.astype(np.float64)\n",
    "            else:\n",
    "                return self.image.astype(np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95080c32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:11:18.362767Z",
     "iopub.status.busy": "2024-01-15T02:11:18.362402Z",
     "iopub.status.idle": "2024-01-15T02:11:18.567426Z",
     "shell.execute_reply": "2024-01-15T02:11:18.566412Z"
    },
    "papermill": {
     "duration": 0.217051,
     "end_time": "2024-01-15T02:11:18.570503",
     "exception": false,
     "start_time": "2024-01-15T02:11:18.353452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1706, 1510]\n",
      "331377 2 332887 2 352509 3 354018 4 355529 3 357040 1 363120 2 364629 4 366138 6 367647 7 369155 9 370664 11 372174 11 373683 12 375193 12 376703 11 378213 10 379723 9 381233 9 381284 1 382744 6 382793 4 384303 4 385813 5 387323 5 388834 4 390345 3 391856 1 396209 3 397719 3 447509 2 497340 1 498848 6 500357 7 501867 6 503378 4 504888 4 506592 2 508101 4 509611 4 511121 4 512632 3 525966 4 527479 3 528990 3 530501 3 532013 1 538357 3 539868 3 541378 4 541451 2 542889 2 542961 3 544090 1 544471 3 545599 1 545982 2 547108 2 548618 1 550127 2 551635 3 553144 4 554654 3 554725 9 556163 3 556233 13 557671 4 557742 15 558030 2 559181 3 559251 17 559539 4 560690 3 560760 18 561048 5 562199 3 562269 19 562558 6 563708 2 563778 19 564068 6 565217 3 565287 20 565578 6 566796 20 567088 6 568178 1 568306 20 568598 4 569687 2 569815 21 570108 3 571324 21 571586 2 571618 2 572834 21 573096 2 574343 21 574606 3 575852 22 576116 4 577361 22 577626 5 578870 23 579136 5 580380 23 580646 5 581889 23 582114 2 582156 6 583399 22 583624 2 583666 6 584909 21 585176 7 586418 21 586687 6 587928 21 588197 6 589437 21 589707 6 590946 22 591217 6 592456 21 592727 6 593966 20 594237 6 595476 19 595748 5 596985 19 598495 17 599916 1 600005 16 601426 1 601515 15 601905 2 602935 2 603024 14 603415 2 604445 3 604534 13 604924 3 605955 2 606044 12 606434 2 607465 2 607554 11 609065 9 610575 8 612086 5 618045 6 619554 9 621063 11 622572 12 624081 13 625591 14 627100 15 628610 15 630120 15 631629 16 633139 17 634649 17 636159 18 637669 18 638128 1 639179 18 639637 2 640689 19 641147 3 642199 19 642658 2 643709 19 644168 2 645219 19 645678 2 646728 20 648220 4 648238 20 649728 7 649748 20 651238 7 651258 20 652747 9 652769 18 654257 9 654279 17 655766 10 655791 15 657276 10 657302 14 658786 10 658812 14 660296 10 660325 10 661806 10 661836 8 663316 10 663347 5 663590 6 664826 10 664859 1 665099 8 666336 9 666609 10 667846 9 668118 13 669356 9 669628 13 670866 9 671138 13 672376 9 672648 13 673886 9 674159 12 675396 8 675669 12 676907 6 677180 11 678419 3 678690 11 680200 10 681711 9 683221 9 684407 1 684732 7 685917 1 686242 7 687427 1 687752 7 688937 1 689263 6 690446 2 690773 6 691956 2 692284 5 693466 1 693794 5 694976 1 695305 4 696486 1 696815 3 697996 1 698326 2 699506 1 701016 1 713695 3 715203 3 716709 5 718218 4 719727 2 721237 2 722747 1 724256 2 725765 2 766305 1 767814 2 769324 3 770833 5 771053 3 772343 5 772562 4 773852 6 774072 4 775361 7 775582 4 776870 9 777092 5 778378 11 778602 5 779886 14 780112 5 781394 17 781622 5 782900 21 783132 5 784407 25 784642 6 785915 27 786153 5 787424 28 787663 6 788932 31 789173 6 790441 32 790684 5 791949 35 792194 5 792218 1 793458 36 793704 5 793726 4 794967 37 795215 4 795235 6 796476 32 796725 3 796745 2 796750 1 797702 2 797986 28 798254 3 799209 8 799495 28 799764 3 800718 11 801005 26 801272 4 802215 3 802227 13 802515 25 802781 4 803725 5 803735 16 804025 24 804291 3 805235 6 805244 19 805534 24 806745 29 807044 22 808255 30 808554 21 809765 30 810064 20 811275 31 811574 19 812785 32 813084 17 814295 33 814594 16 815805 33 816105 14 816325 8 817316 32 817616 12 817833 12 818826 31 819126 10 819342 15 820337 29 820637 8 820851 18 821848 28 822149 4 822360 20 823361 24 823870 21 824872 23 825379 23 826383 21 826888 25 827895 18 828398 25 829406 16 829909 24 830918 14 831420 23 832430 10 832931 22 833943 6 834442 21 835953 20 837467 16 838980 12 840493 8 846652 1 848162 1 860234 3 861743 4 863253 3 870156 1 871665 3 873175 4 874685 5 876195 6 877706 5 879216 6 880727 6 882237 6 882914 1 883747 6 884424 1 885258 5 885933 2 886768 6 887443 1 888279 5 888953 1 889789 6 890463 1 891300 5 891973 1 892811 4 893483 1 894322 3 894993 1 899523 1 901031 3 902540 4 904049 5 905560 5 907070 5 910079 3 911588 4 913098 4 914608 3 916118 3 917628 3 919139 3 920650 2 926694 2 928205 2 929715 2 931226 2 1067039 1 1068540 2 1068545 6 1070037 3 1070048 13 1071543 9 1071555 17 1073049 33 1074555 36 1076063 38 1077570 41 1079079 41 1080587 42 1082096 43 1083606 42 1085115 42 1086624 42 1088134 40 1089644 36 1091154 32 1092664 23 1092692 1 1094174 21 1095684 19 1097194 13 1098705 8 1100215 7 1101726 5 1103237 3 1127567 2 1133653 2 1135163 2 1137511 1 1139019 3 1140527 4 1142035 7 1142434 3 1143544 6 1143942 5 1145052 7 1145452 5 1146559 7 1146963 3 1148066 8 1148474 1 1149574 8 1151068 10 1151082 8 1152579 18 1154088 16 1165125 2 1166635 2 1168145 3 1169656 2 1190859 1 1191048 1 1192369 2 1196454 6 1197962 7 1199471 7 1200981 7 1201565 1 1202490 7 1203075 1 1203999 7 1205508 7 1207016 8 1208525 8 1210034 8 1211543 8 1213053 7 1214562 7 1216072 6 1217581 6 1218169 1 1218203 1 1219090 6 1219679 1 1219713 2 1220599 6 1221187 2 1221223 4 1222108 6 1222697 1 1222734 4 1223617 6 1224207 1 1224245 1 1224250 1 1225126 7 1225717 1 1225759 3 1226635 7 1227227 2 1227256 2 1227269 3 1228145 6 1228738 1 1228766 3 1228780 1 1229654 7 1230276 4 1231163 8 1231786 5 1231805 2 1232672 8 1233297 3 1233315 2 1234182 7 1234826 2 1235691 8 1236337 2 1237200 9 1237848 2 1238709 9 1240219 9 1241729 9 1243238 9 1244747 10 1246256 11 1247766 10 1249275 10 1250784 10 1252293 11 1253803 10 1255312 11 1256822 10 1258332 9 1259841 9 1261352 8 1262862 1 1262865 4 1284464 1 1285973 3 1287482 5 1288991 6 1290500 7 1292009 7 1293518 8 1295027 9 1296537 9 1298046 10 1299556 11 1301065 15 1302575 17 1304085 19 1305595 21 1307105 22 1308615 24 1310125 25 1311636 24 1313147 23 1314658 22 1316170 19 1316369 1 1317684 15 1319199 9 1328361 4 1329869 7 1331377 10 1332886 11 1334394 12 1335903 13 1337412 12 1338921 12 1340430 12 1341939 12 1343448 13 1344956 12 1346464 12 1347963 22 1349473 19 1350985 15 1351052 2 1352496 13 1352559 5 1354009 9 1354067 8 1355576 9 1357085 10 1358594 10 1360104 10 1361614 8 1362438 7 1363123 8 1363946 11 1364633 6 1365454 14 1366143 5 1366963 16 1367653 5 1368473 17 1369164 3 1369982 19 1371491 21 1373001 22 1374511 23 1376021 24 1377532 24 1379043 24 1380555 23 1382066 22 1383577 22 1384265 2 1385088 22 1385773 6 1386601 20 1387283 7 1388113 19 1388793 7 1389624 20 1390304 6 1391135 21 1391815 3 1392646 22 1394162 32 1395678 26 1397190 24 1398703 20 1398787 2 1400215 17 1400294 6 1401727 14 1401804 6 1403240 8 1403313 7 1404822 9 1406332 9 1406502 1 1407843 8 1408011 8 1409353 8 1409519 18 1410862 9 1411027 20 1412372 9 1412535 20 1413882 8 1414043 18 1415391 9 1415550 18 1416902 8 1417057 18 1417491 4 1418412 8 1418565 17 1419000 5 1419923 7 1420072 16 1420509 6 1421433 7 1421580 15 1422018 6 1422944 5 1423088 14 1423528 6 1424455 4 1424597 13 1425038 4 1425966 3 1426105 13 1426548 5 1427476 3 1427613 13 1428058 5 1428987 1 1429095 39 1429568 4 1430497 1 1430605 38 1431078 4 1432007 1 1432115 36 1432589 3 1433625 34 1435135 32 1436645 30 1438155 29 1438671 1 1439665 28 1440160 3 1440181 2 1441175 27 1441671 3 1442685 26 1443182 3 1444195 25 1444693 2 1445705 24 1447215 23 1448725 22 1450235 21 1451744 21 1453254 20 1454764 20 1456274 19 1457784 19 1459293 19 1460803 19 1462313 19 1463822 20 1465332 20 1466841 20 1468351 19 1469860 19 1471372 16 1472884 14 1474406 1 1496021 3 1497531 3 1579053 3 1580563 3 1582074 1 1586162 1 1587671 2 1589180 3 1590692 1 1591125 4 1592635 5 1594145 6 1595655 7 1596636 1 1597165 7 1598146 1 1598675 7 1600185 7 1601695 7 1603206 6 1604716 5 1606227 3 1607307 2 1607738 1 1608817 2 1616294 2 1616303 2 1617804 2 1625521 1 1627029 7 1628539 8 1628904 3 1630048 10 1630415 1 1631558 11 1633068 12 1633434 1 1634579 11 1634943 2 1636089 12 1636454 2 1636510 4 1637599 12 1637964 2 1638019 5 1639109 12 1639474 2 1640619 12 1640984 2 1642130 12 1642493 3 1643641 11 1644003 1 1644005 1 1644033 2 1645151 12 1645500 4 1645512 1 1645515 2 1645541 4 1646662 11 1647011 3 1647021 6 1647050 5 1648172 11 1648523 3 1648530 8 1648560 1 1649683 11 1650034 14 1650088 3 1651194 10 1651545 12 1651597 4 1652704 11 1653056 11 1653105 6 1654215 10 1654567 8 1654612 9 1655725 11 1656077 7 1656122 9 1657236 10 1657587 7 1657633 7 1658747 10 1659098 5 1659143 6 1660258 9 1660608 3 1661608 2 1661768 10 1663118 3 1663279 9 1664629 2 1664790 9 1666300 9 1667811 9 1669322 8 1670669 2 1670833 8 1672179 1 1672344 7 1673857 5 1675369 3 1676780 1 1678289 2 1695425 3 1696935 3 1697916 4 1698445 3 1699424 4 1726564 1 1728074 1 1731678 2 1733188 1 1741894 5 1743403 7 1744912 8 1746421 9 1747930 10 1749439 11 1750948 12 1752457 13 1753966 14 1755476 13 1756985 13 1758495 13 1760005 12 1761515 12 1763025 11 1763063 1 1764535 11 1764571 4 1766046 8 1766081 5 1767559 2 1767591 5 1769101 6 1770611 7 1772121 7 1773631 8 1775141 9 1776651 10 1778162 11 1779673 14 1781184 22 1782694 29 1784205 31 1785715 35 1787226 36 1788738 35 1790249 36 1791761 36 1791821 2 1793273 35 1793321 4 1793330 9 1793345 6 1794786 33 1794830 32 1796298 33 1796333 40 1797809 22 1797834 51 1797892 1 1799320 19 1799346 52 1799399 4 1799457 2 1800832 15 1800858 54 1800965 4 1802343 13 1802370 54 1802448 12 1802463 3 1802472 7 1803854 11 1803881 53 1803957 32 1805364 11 1805392 52 1805467 32 1806875 9 1806904 41 1806947 7 1806976 32 1808385 9 1808421 31 1808460 4 1808486 31 1809895 9 1809938 21 1809996 29 1811405 9 1811453 8 1811506 28 1812916 8 1813017 23 1814426 9 1814528 20 1814597 3 1815936 9 1816108 4 1817446 10 1817618 7 1818957 9 1819129 9 1820467 8 1820639 10 1821977 8 1822149 11 1823487 8 1823659 12 1824998 6 1825106 3 1825170 10 1826509 5 1826616 4 1826680 10 1826693 2 1828019 6 1828059 1 1828125 5 1828190 10 1828202 3 1829529 6 1829635 6 1829701 7 1829712 4 1831040 5 1831146 4 1831211 6 1831222 5 1832551 4 1832626 2 1832657 3 1832732 7 1834242 10 1835752 13 1837262 15 1837283 2 1838772 17 1838792 4 1840283 23 1841794 22 1843305 21 1844817 18 1846329 15 1847840 14 1849353 10 1862684 2 1862938 2 1862945 4 1864193 5 1864448 2 1864456 3 1865703 5 1867213 5 1868723 6 1870232 6 1871742 6 1873253 4 1897330 2 1897405 1 1898839 3 1898914 2 1900349 3 1900423 2 1901859 3 1901932 3 1907967 2 1909477 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = label_files_kidney_3_dense[1]\n",
    "    img_processor = ImageProcessor(path)\n",
    "    label = img_processor.display_images(normalized=False, array = True)\n",
    "    print(list(label.shape))\n",
    "    r = rle_encode(label)\n",
    "    print(r)\n",
    "    rev = rle_decode(r, label.shape)\n",
    "    \n",
    "    del r\n",
    "    del rev\n",
    "    del label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da3315aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:11:18.590476Z",
     "iopub.status.busy": "2024-01-15T02:11:18.589438Z",
     "iopub.status.idle": "2024-01-15T02:11:25.237547Z",
     "shell.execute_reply": "2024-01-15T02:11:25.236486Z"
    },
    "papermill": {
     "duration": 6.660781,
     "end_time": "2024-01-15T02:11:25.240044",
     "exception": false,
     "start_time": "2024-01-15T02:11:18.579263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "from skimage import io\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7856c86",
   "metadata": {
    "papermill": {
     "duration": 0.008874,
     "end_time": "2024-01-15T02:11:25.258073",
     "exception": false,
     "start_time": "2024-01-15T02:11:25.249199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Two methods to create tensor from tiff images, both are giving different results so I am not sure which one to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3692a43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:11:25.276918Z",
     "iopub.status.busy": "2024-01-15T02:11:25.276335Z",
     "iopub.status.idle": "2024-01-15T02:11:25.280567Z",
     "shell.execute_reply": "2024-01-15T02:11:25.279762Z"
    },
    "papermill": {
     "duration": 0.015581,
     "end_time": "2024-01-15T02:11:25.282398",
     "exception": false,
     "start_time": "2024-01-15T02:11:25.266817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image_list = []\n",
    "# for image in os.listdir(paths['kidney_2'][0]):\n",
    "#     image_path = os.path.join(paths['kidney_2'][0], image)\n",
    "#     img = io.imread(image_path)\n",
    "#     img.size((1024,1024))\n",
    "#     image_list.append(img)\n",
    "\n",
    "#     # Convert the list of images to a NumPy array\n",
    "# img_tensor = np.stack(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46f5a97b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:11:25.300348Z",
     "iopub.status.busy": "2024-01-15T02:11:25.300066Z",
     "iopub.status.idle": "2024-01-15T02:11:25.304032Z",
     "shell.execute_reply": "2024-01-15T02:11:25.303133Z"
    },
    "papermill": {
     "duration": 0.015134,
     "end_time": "2024-01-15T02:11:25.305998",
     "exception": false,
     "start_time": "2024-01-15T02:11:25.290864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  def pad_or_truncate(numbers_list, target_length):\n",
    "#     if len(numbers_list) < target_length:\n",
    "#         # Pad with zeros\n",
    "#         numbers_list += [0.0] * (target_length - len(numbers_list))\n",
    "#     elif len(numbers_list) > target_length:\n",
    "#         # Truncate\n",
    "#         numbers_list = numbers_list[:target_length]\n",
    "#     return numbers_list\n",
    "\n",
    "# max_length = 268"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acde6b18",
   "metadata": {
    "papermill": {
     "duration": 0.008254,
     "end_time": "2024-01-15T02:11:25.322987",
     "exception": false,
     "start_time": "2024-01-15T02:11:25.314733",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is the method to convert label to tensor but I am not sure if its correct or not because the numbers in the encoded label represents position(I guess??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24097560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:11:25.340676Z",
     "iopub.status.busy": "2024-01-15T02:11:25.340426Z",
     "iopub.status.idle": "2024-01-15T02:11:25.344357Z",
     "shell.execute_reply": "2024-01-15T02:11:25.343495Z"
    },
    "papermill": {
     "duration": 0.014967,
     "end_time": "2024-01-15T02:11:25.346186",
     "exception": false,
     "start_time": "2024-01-15T02:11:25.331219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# label_list = []\n",
    "# for label in os.listdir(paths['kidney_2'][1]):\n",
    "#     label_path = image_path = os.path.join(paths['kidney_2'][1], image)\n",
    "#     lbl = tiff.imread(label_path)\n",
    "    \n",
    "#     encoded_label = rle_encode(lbl)\n",
    "#     numbers_list = [float(num) for num in encoded_label.split()]\n",
    "#     label_list.append(numbers_list)\n",
    "    \n",
    "# label_tensor = torch.tensor(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aba1b0ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:11:25.364582Z",
     "iopub.status.busy": "2024-01-15T02:11:25.363932Z",
     "iopub.status.idle": "2024-01-15T02:11:25.369148Z",
     "shell.execute_reply": "2024-01-15T02:11:25.368338Z"
    },
    "papermill": {
     "duration": 0.016348,
     "end_time": "2024-01-15T02:11:25.371043",
     "exception": false,
     "start_time": "2024-01-15T02:11:25.354695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_to_tensor(path):\n",
    "    #empty list to hold tensors(placeholder)\n",
    "    tensor_list = []\n",
    "    \n",
    "    for image in os.listdir(path):\n",
    "        image_path = os.path.join(path, image)\n",
    "        img = io.imread(image_path)\n",
    "        img.resize((1024,1024))\n",
    "        tensor_list.append(img)\n",
    "\n",
    "    # Convert the list of images to a NumPy array\n",
    "    img_tensor = np.stack(tensor_list)\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9aa9458a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:11:25.389454Z",
     "iopub.status.busy": "2024-01-15T02:11:25.389211Z",
     "iopub.status.idle": "2024-01-15T02:14:26.108344Z",
     "shell.execute_reply": "2024-01-15T02:14:26.107185Z"
    },
    "papermill": {
     "duration": 180.731629,
     "end_time": "2024-01-15T02:14:26.111193",
     "exception": false,
     "start_time": "2024-01-15T02:11:25.379564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Converting images to tensor\n",
    "\n",
    "images_kidney_1_dense = image_to_tensor(paths['kidney_1_dense'][0])\n",
    "images_kideny_1_voi = image_to_tensor(paths['kidney_1_voi'][0])\n",
    "stack_images = np.vstack((images_kidney_1_dense, images_kideny_1_voi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efc4b8a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:14:26.131453Z",
     "iopub.status.busy": "2024-01-15T02:14:26.131144Z",
     "iopub.status.idle": "2024-01-15T02:14:26.183672Z",
     "shell.execute_reply": "2024-01-15T02:14:26.182782Z"
    },
    "papermill": {
     "duration": 0.064139,
     "end_time": "2024-01-15T02:14:26.185529",
     "exception": false,
     "start_time": "2024-01-15T02:14:26.121390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del images_kidney_1_dense\n",
    "del images_kideny_1_voi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d7f3d83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:14:26.204339Z",
     "iopub.status.busy": "2024-01-15T02:14:26.204043Z",
     "iopub.status.idle": "2024-01-15T02:15:54.555321Z",
     "shell.execute_reply": "2024-01-15T02:15:54.554156Z"
    },
    "papermill": {
     "duration": 88.363726,
     "end_time": "2024-01-15T02:15:54.558223",
     "exception": false,
     "start_time": "2024-01-15T02:14:26.194497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_kidney_2 = image_to_tensor(paths['kidney_2'][0])\n",
    "stack_images = np.vstack((images_kidney_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e4c137f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:15:54.577683Z",
     "iopub.status.busy": "2024-01-15T02:15:54.577376Z",
     "iopub.status.idle": "2024-01-15T02:15:54.656477Z",
     "shell.execute_reply": "2024-01-15T02:15:54.655701Z"
    },
    "papermill": {
     "duration": 0.090801,
     "end_time": "2024-01-15T02:15:54.658439",
     "exception": false,
     "start_time": "2024-01-15T02:15:54.567638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del images_kidney_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ff8c878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:15:54.676639Z",
     "iopub.status.busy": "2024-01-15T02:15:54.676365Z",
     "iopub.status.idle": "2024-01-15T02:17:00.204859Z",
     "shell.execute_reply": "2024-01-15T02:17:00.203645Z"
    },
    "papermill": {
     "duration": 65.540348,
     "end_time": "2024-01-15T02:17:00.207317",
     "exception": false,
     "start_time": "2024-01-15T02:15:54.666969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_kidney_3_dense = image_to_tensor(paths['kidney_3_dense'][0])\n",
    "images_kidney_3_sparse = image_to_tensor(paths['kidney_3_sparse'][0])\n",
    "stack_images = np.vstack((images_kidney_3_dense, images_kidney_3_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f63c1198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:17:00.226204Z",
     "iopub.status.busy": "2024-01-15T02:17:00.225837Z",
     "iopub.status.idle": "2024-01-15T02:17:00.240219Z",
     "shell.execute_reply": "2024-01-15T02:17:00.239375Z"
    },
    "papermill": {
     "duration": 0.025879,
     "end_time": "2024-01-15T02:17:00.242176",
     "exception": false,
     "start_time": "2024-01-15T02:17:00.216297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del images_kidney_3_dense\n",
    "del images_kidney_3_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a22aefcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:17:00.260417Z",
     "iopub.status.busy": "2024-01-15T02:17:00.260162Z",
     "iopub.status.idle": "2024-01-15T02:18:26.727883Z",
     "shell.execute_reply": "2024-01-15T02:18:26.726960Z"
    },
    "papermill": {
     "duration": 86.479504,
     "end_time": "2024-01-15T02:18:26.730252",
     "exception": false,
     "start_time": "2024-01-15T02:17:00.250748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Converting to masks to tensor\n",
    "\n",
    "masks_kidney_1_dense = image_to_tensor(paths['kidney_1_dense'][1])\n",
    "masks_kidney_1_voi = image_to_tensor(paths['kidney_1_voi'][1])\n",
    "stack_masks = np.vstack((masks_kidney_1_dense, masks_kidney_1_voi))\n",
    "del masks_kidney_1_dense\n",
    "del masks_kidney_1_voi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfd2c5ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:18:26.750104Z",
     "iopub.status.busy": "2024-01-15T02:18:26.749808Z",
     "iopub.status.idle": "2024-01-15T02:19:11.682857Z",
     "shell.execute_reply": "2024-01-15T02:19:11.681914Z"
    },
    "papermill": {
     "duration": 44.945107,
     "end_time": "2024-01-15T02:19:11.685318",
     "exception": false,
     "start_time": "2024-01-15T02:18:26.740211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "masks_kidney_2 = image_to_tensor(paths['kidney_2'][1])\n",
    "stack_masks = np.vstack((masks_kidney_2))\n",
    "del masks_kidney_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb63d331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:19:11.705492Z",
     "iopub.status.busy": "2024-01-15T02:19:11.705191Z",
     "iopub.status.idle": "2024-01-15T02:19:44.172577Z",
     "shell.execute_reply": "2024-01-15T02:19:44.171765Z"
    },
    "papermill": {
     "duration": 32.480023,
     "end_time": "2024-01-15T02:19:44.174954",
     "exception": false,
     "start_time": "2024-01-15T02:19:11.694931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "masks_kidney_3_dense = image_to_tensor(paths['kidney_3_dense'][1])\n",
    "masks_kidney_3_sparse = image_to_tensor(paths['kidney_3_sparse'][1])\n",
    "stack_masks = np.vstack((masks_kidney_3_dense, masks_kidney_3_sparse))\n",
    "del masks_kidney_3_dense\n",
    "del masks_kidney_3_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc55ee8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:19:44.279395Z",
     "iopub.status.busy": "2024-01-15T02:19:44.278989Z",
     "iopub.status.idle": "2024-01-15T02:19:44.340628Z",
     "shell.execute_reply": "2024-01-15T02:19:44.339630Z"
    },
    "papermill": {
     "duration": 0.078602,
     "end_time": "2024-01-15T02:19:44.347537",
     "exception": false,
     "start_time": "2024-01-15T02:19:44.268935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                     Type              Data/Info\n",
      "--------------------------------------------------------\n",
      "Image                        module            <module 'PIL.Image' from <...>e-packages/PIL/Image.py'>\n",
      "ImageProcessor               type              <class '__main__.ImageProcessor'>\n",
      "ToTensor                     type              <class 'torchvision.trans<...>rms.transforms.ToTensor'>\n",
      "data_dir                     str               /kaggle/input/blood-vessel-segmentation/\n",
      "dataset                      list              n=5\n",
      "df_train_rles                DataFrame                                 i<...>\\n[7429 rows x 2 columns]\n",
      "display                      function          <function display at 0x788dcea9ec20>\n",
      "glob                         module            <module 'glob' from '/opt<...>/lib/python3.10/glob.py'>\n",
      "i                            int               1034\n",
      "image_files_kidney_3_dense   list              n=501\n",
      "image_to_tensor              function          <function image_to_tensor at 0x788c5a98f1c0>\n",
      "images_path                  str               /kaggle/input/blood-vesse<...>in/kidney_3_sparse/images\n",
      "img_processor                ImageProcessor    <__main__.ImageProcessor <...>object at 0x788d03ee8940>\n",
      "io                           module            <module 'skimage.io' from<...>/skimage/io/__init__.py'>\n",
      "j                            int               500\n",
      "key                          str               kidney_3_sparse\n",
      "l                            list              n=501\n",
      "label_files_kidney_3_dense   list              n=501\n",
      "labels_path                  str               /kaggle/input/blood-vesse<...>ain/kidney_3_dense/labels\n",
      "mpimg                        module            <module 'matplotlib.image<...>ges/matplotlib/image.py'>\n",
      "np                           module            <module 'numpy' from '/op<...>kages/numpy/__init__.py'>\n",
      "os                           module            <module 'os' from '/opt/c<...>da/lib/python3.10/os.py'>\n",
      "path                         str               /kaggle/input/blood-vesse<...>y_3_dense/labels/0497.tif\n",
      "paths                        dict              n=5\n",
      "pd                           module            <module 'pandas' from '/o<...>ages/pandas/__init__.py'>\n",
      "plt                          module            <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "rle_decode                   function          <function rle_decode at 0x788cf9d1cf70>\n",
      "rle_encode                   function          <function rle_encode at 0x788cf9d1cee0>\n",
      "stack_images                 ndarray           2070x1024x1024: 2170552320 elems, type `uint16`, 4341104640 bytes (4140.0 Mb)\n",
      "stack_masks                  ndarray           1536x1024x1024: 1610612736 elems, type `uint8`, 1610612736 bytes (1536.0 Mb)\n",
      "tf                           module            <module 'tensorflow' from<...>/tensorflow/__init__.py'>\n",
      "tiff                         module            <module 'tifffile' from '<...>es/tifffile/__init__.py'>\n",
      "time                         module            <module 'time' (built-in)>\n",
      "torch                        module            <module 'torch' from '/op<...>kages/torch/__init__.py'>\n",
      "train_data_path              str               /kaggle/input/blood-vessel-segmentation//train\n",
      "transforms                   module            <module 'torchvision.tran<...>/transforms/__init__.py'>\n",
      "value1                       str               /kaggle/input/blood-vesse<...>in/kidney_3_sparse/images\n",
      "value2                       str               /kaggle/input/blood-vesse<...>in/kidney_3_sparse/labels\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3781c3d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T02:19:44.368687Z",
     "iopub.status.busy": "2024-01-15T02:19:44.368300Z",
     "iopub.status.idle": "2024-01-15T02:19:44.374471Z",
     "shell.execute_reply": "2024-01-15T02:19:44.373411Z"
    },
    "papermill": {
     "duration": 0.020443,
     "end_time": "2024-01-15T02:19:44.376828",
     "exception": false,
     "start_time": "2024-01-15T02:19:44.356385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def label_to_tensor(path):\n",
    "#     #empty list to hold tensors(placeholder)\n",
    "#     tensor_list = []\n",
    "    \n",
    "#     for label in os.listdir(path):\n",
    "#         label_path = os.path.join(path, label)\n",
    "#         lbl = tiff.imread(label_path)\n",
    "#         lbl.resize((1024, 1024))\n",
    "\n",
    "#         encoded_label = rle_encode(lbl)\n",
    "#         numbers_list = [float(num) for num in encoded_label.split()]\n",
    "#         numbers_list = pad_or_truncate(numbers_list, max_length)\n",
    "#         tesnor_list.append(numbers_list)      \n",
    "    \n",
    "#     #stacking the list of tensor into single tensor\n",
    "#     label_tesnor = torch.stack(tensor_list)\n",
    "#     return label_tensor "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 6962461,
     "sourceId": 61446,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 535.547936,
   "end_time": "2024-01-15T02:19:47.399093",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-15T02:10:51.851157",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
